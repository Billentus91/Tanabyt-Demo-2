# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UsM0ilw0mstipJYYsIk3q6WLUpx-gWJF
"""

import streamlit as st
import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import tensorflow as tf
from tensorflow.keras.models import load_model
import pickle
import joblib # Import the joblib library
import matplotlib.pyplot as plt
import io

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# --- Streamlit App Configuration ---
st.set_page_config(layout="wide")
st.title("Tanabyt Forecasting")
st.markdown("### Predicting Volatility using an LSTM Model")

# --- Helper Functions from the Notebook ---

@st.cache_data
def load_and_preprocess_data(ticker):
    """
    Loads, cleans, and preprocesses stock data from Yahoo Finance.
    This function mirrors the logic in the provided notebook.
    """
    try:
        data = yf.download(ticker, period='5y')
        if data.empty:
            st.error(f"No data retrieved for {ticker}")
            return None, None

        # Clean and preprocess
        df = data.copy()
        df = df[~df.index.duplicated(keep='last')]
        df = df.sort_index()
        core_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
        df[core_columns] = df[core_columns].ffill()
        df = df.dropna(subset=core_columns)
        price_cols = ['Open', 'High', 'Low', 'Close']
        df = df[(df[price_cols] > 0).all(axis=1)]
        df['price_change'] = df['Close'].pct_change()
        df['price_change'] = df['price_change'].clip(-0.5, 0.5)

        if 'Volume' in df.columns:
            median_volume = df['Volume'][df['Volume'] > 0].median()
            df.loc[df['Volume'] <= 0, 'Volume'] = median_volume

        # Feature engineering
        df['returns'] = df['Close'].pct_change()
        df['volatility'] = df['returns'].rolling(window=5).std() * np.sqrt(5)
        df['sma_10'] = df['Close'].rolling(window=10).mean()
        df['sma_20'] = df['Close'].rolling(window=20).mean()
        df['price_ratio'] = df['Close'] / df['sma_20']
        df['volume_sma'] = df['Volume'].rolling(window=10).mean()
        df['volume_ratio'] = df['Volume'] / df['volume_sma']
        df['momentum_5'] = df['Close'] / df['Close'].shift(5)
        df['momentum_10'] = df['Close'] / df['Close'].shift(10)
        df['hl_ratio'] = (df['High'] - df['Low']) / df['Close']
        df['ticker'] = ticker
        df.columns.name = None
        df = df.dropna()

        # Add lag features
        for lag in [1, 2, 3, 5]:
            df[f'volatility_lag_{lag}'] = df['volatility'].shift(lag)
        df['volatility_ma_5'] = df['volatility'].rolling(window=5).mean()
        df['volatility_ma_10'] = df['volatility'].rolling(window=10).mean()
        df['volatility_std_5'] = df['volatility'].rolling(window=5).std()
        for lag in [1, 2, 3]:
            df[f'returns_lag_{lag}'] = df['returns'].shift(lag)

        df = df.dropna()

        # Define features and target
        feature_columns = [
            'returns', 'price_ratio', 'volume_ratio', 'momentum_5', 'momentum_10',
            'hl_ratio', 'volatility_lag_1', 'volatility_lag_2', 'volatility_lag_3',
            'volatility_lag_5', 'volatility_ma_5', 'volatility_ma_10', 'volatility_std_5',
            'returns_lag_1', 'returns_lag_2', 'returns_lag_3'
        ]
        target_column = 'volatility'

        return df, feature_columns, target_column

# --- Sidebar for User Input ---
st.sidebar.header("User Input")
stock_option = st.sidebar.selectbox(
    "Select a stock:",
    ("QQQ", "SPY")
)

forecast_period = st.sidebar.slider(
    "Select volatility forecast period (days):",
    min_value=5, max_value=10, value=5, step=5
)

# --- Load Models and Scalers ---
try:
    if stock_option == "QQQ":
        model_path = "qqq_model.keras"
        feature_scaler_path = "qqq_feature_scaler.joblib"
        target_scaler_path = "qqq_target_scaler.joblib"
    else:
        model_path = "spy_model.keras"
        feature_scaler_path = "spy_feature_scaler.joblib"
        target_scaler_path = "spy_target_scaler.joblib"

    model = load_model(model_path)
    # Load scalers using joblib
    feature_scaler = joblib.load(feature_scaler_path)
    target_scaler = joblib.load(target_scaler_path)

except FileNotFoundError:
    st.error("Model or scaler files not found. Please make sure the files exist and have the correct '.keras' and '.joblib' extensions.")
    st.stop()

# --- Data Fetching and Prediction Logic ---
if stock_option and model:
    st.subheader(f"Analyzing {stock_option}")
    data, feature_columns, target_column = load_and_preprocess_data(stock_option)

    if data is not None:
        st.write("### Actual vs Predicted Volatility")

        # Get the latest data for prediction
        sequence_length = 10
        latest_data = data[feature_columns + [target_column]].tail(sequence_length + forecast_period)

        # Separate into data for prediction and historical values
        historical_data = latest_data.iloc[:sequence_length]

        # Prepare for prediction
        X_pred_raw = latest_data[feature_columns].values
        X_pred_scaled = feature_scaler.transform(X_pred_raw.reshape(-1, len(feature_columns)))

        # Reshape for LSTM input
        X_pred_scaled_reshaped = X_pred_scaled.reshape(X_pred_raw.shape[0], 1, X_pred_raw.shape[1])

        # Make predictions
        predicted_scaled = model.predict(X_pred_scaled_reshaped, verbose=0)
        predicted_volatility = target_scaler.inverse_transform(predicted_scaled).flatten()

        # Combine actual and predicted for plotting
        plot_data = pd.DataFrame({
            "Actual Volatility": data[target_column].tail(forecast_period),
            "Predicted Volatility": predicted_volatility[-forecast_period:]
        }, index=data.index[-forecast_period:])

        # Plotting with Streamlit's line_chart
        st.line_chart(plot_data)

        # --- Display Metrics ---
        st.write("### Model Metrics")

        # These are the metrics from the provided notebook for demonstration.
        # In a real-world app, you might re-evaluate on the latest data.
        if stock_option == "QQQ":
            metrics_data = {
                'Metric': ['MSE', 'RMSE', 'MAE', 'R²'],
                'QQQ Train': [0.000057, 0.007544, 0.005661, 0.752383],
                'QQQ Test': [0.000109, 0.010437, 0.006647, 0.764282]
            }
        else: # SPY
            metrics_data = {
                'Metric': ['MSE', 'RMSE', 'MAE', 'R²'],
                'SPY Train': [0.000036, 0.005980, 0.004293, 0.720412],
                'SPY Test': [0.000088, 0.009363, 0.005570, 0.770471]
            }

        metrics_df = pd.DataFrame(metrics_data)
        st.table(metrics_df)