# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UsM0ilw0mstipJYYsIk3q6WLUpx-gWJF
"""

import streamlit as st
import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import tensorflow as tf
from tensorflow.keras.models import load_model
import pickle
import joblib  # Import the joblib library
import matplotlib.pyplot as plt
import io
import os

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# --- Helper Functions from the Notebook ---

@st.cache_data
def load_and_preprocess_data(ticker):
    """
    Loads, cleans, and preprocesses stock data from Yahoo Finance.
    This function mirrors the logic in the provided notebook.
    """
    try:
        data = yf.download(ticker, period='5y')
        if data.empty:
            st.error(f"No data retrieved for {ticker}")
            return None, None, None

        # Clean and preprocess
        df = data.copy()
        df = df[~df.index.duplicated(keep='last')]
        df = df.sort_index()
        core_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
        df[core_columns] = df[core_columns].ffill()
        df = df.dropna(subset=core_columns)
        price_cols = ['Open', 'High', 'Low', 'Close']
        df = df[(df[price_cols] > 0).all(axis=1)]
        df['price_change'] = df['Close'].pct_change()
        df['price_change'] = df['price_change'].clip(-0.5, 0.5)

        if 'Volume' in df.columns:
            median_volume = df['Volume'][df['Volume'] > 0].median()
            df.loc[df['Volume'] <= 0, 'Volume'] = median_volume

        # Feature engineering
        df['returns'] = df['Close'].pct_change()
        df['volatility'] = df['returns'].rolling(window=5).std() * np.sqrt(5)
        df['sma_10'] = df['Close'].rolling(window=10).mean()
        df['sma_20'] = df['Close'].rolling(window=20).mean()
        df['price_ratio'] = df['Close'] / df['sma_20']
        df['volume_sma'] = df['Volume'].rolling(window=10).mean()
        df['volume_ratio'] = df['Volume'] / df['volume_sma']
        df['momentum_5'] = df['Close'] / df['Close'].shift(5)
        df['momentum_10'] = df['Close'] / df['Close'].shift(10)
        df['hl_ratio'] = (df['High'] - df['Low']) / df['Close']
        df['ticker'] = ticker
        df.columns.name = None
        df = df.dropna()

        # Add lag features
        for lag in [1, 2, 3, 5]:
            df[f'volatility_lag_{lag}'] = df['volatility'].shift(lag)
        df['volatility_ma_5'] = df['volatility'].rolling(window=5).mean()
        df['volatility_ma_10'] = df['volatility'].rolling(window=10).mean()
        df['volatility_std_5'] = df['volatility'].rolling(window=5).std()
        for lag in [1, 2, 3]:
            df[f'returns_lag_{lag}'] = df['returns'].shift(lag)

        df = df.dropna()

        # Define features and target
        feature_columns = [
            'returns', 'price_ratio', 'volume_ratio', 'momentum_5', 'momentum_10',
            'hl_ratio', 'volatility_lag_1', 'volatility_lag_2', 'volatility_lag_3',
            'volatility_lag_5', 'volatility_ma_5', 'volatility_ma_10', 'volatility_std_5',
            'returns_lag_1', 'returns_lag_2', 'returns_lag_3'
        ]
        target_column = 'volatility'

        return df, feature_columns, target_column

    except Exception as e:
        st.error(f"Error loading data for {ticker}: {str(e)}")
        return None, None, None

def create_demo_model_and_scalers(stock_option, feature_columns):
    """
    Creates demo model and scalers when the actual files don't exist.
    """
    try:
        # Create a simple demo LSTM model
        model = tf.keras.Sequential([
            tf.keras.layers.LSTM(50, input_shape=(1, len(feature_columns))),
            tf.keras.layers.Dense(1)
        ])
        model.compile(optimizer='adam', loss='mse')

        # Create demo scalers
        feature_scaler = MinMaxScaler()
        target_scaler = MinMaxScaler()

        # Fit with dummy data
        dummy_features = np.random.randn(100, len(feature_columns))
        dummy_target = np.random.randn(100, 1)

        feature_scaler.fit(dummy_features)
        target_scaler.fit(dummy_target)

        return model, feature_scaler, target_scaler

    except Exception as e:
        st.error(f"Error creating demo model: {str(e)}")
        return None, None, None

# --- Main Streamlit App Function ---
def main():
    st.set_page_config(layout="wide")
    st.title("Tanabyt Forecasting")
    st.markdown("### Predicting using an LSTM Model")

    # --- Sidebar for User Input ---
    st.sidebar.header("User Input")
    stock_option = st.sidebar.selectbox(
        "Select a stock:",
        ("QQQ", "SPY")
    )

    forecast_period = st.sidebar.slider(
        "Select volatility forecast period (days):",
        min_value=5, max_value=10, value=5, step=5
    )

    # --- Load Models and Scalers and Run App Logic ---
    try:
        if stock_option == "QQQ":
            model_path = "qqq_model.keras"
            feature_scaler_path = "qqq_feature_scaler.joblib"
            target_scaler_path = "qqq_target_scaler.joblib"
        else:
            model_path = "spy_model.keras"
            feature_scaler_path = "spy_feature_scaler.joblib"
            target_scaler_path = "spy_target_scaler.joblib"

        # Check if model files exist
        model_exists = os.path.exists(model_path)
        feature_scaler_exists = os.path.exists(feature_scaler_path)
        target_scaler_exists = os.path.exists(target_scaler_path)

        if not (model_exists and feature_scaler_exists and target_scaler_exists):
            st.warning("Model files not found. Using demo model for demonstration purposes.")

            # Load data first to get feature columns for demo model
            data, feature_columns, target_column = load_and_preprocess_data(stock_option)
            if data is None:
                st.error("Unable to load stock data.")
                return

            model, feature_scaler, target_scaler = create_demo_model_and_scalers(stock_option, feature_columns)
            if model is None:
                st.error("Unable to create demo model.")
                return
        else:
            # Load the trained model and scalers
            model = load_model(model_path)
            feature_scaler = joblib.load(feature_scaler_path)
            target_scaler = joblib.load(target_scaler_path)

            # Load data
            data, feature_columns, target_column = load_and_preprocess_data(stock_option)

        # --- Data Fetching and Prediction Logic ---
        if stock_option and model and data is not None:
            st.subheader(f"Analyzing {stock_option}")

            # Check if we have enough data
            sequence_length = 10
            min_required_data = sequence_length + forecast_period

            if len(data) < min_required_data:
                st.error(f"Insufficient data. Need at least {min_required_data} data points, but only have {len(data)}.")
                return

            st.write("### Actual vs Predicted Volatility")

            # Get the latest data for prediction
            latest_data = data[feature_columns + [target_column]].tail(sequence_length + forecast_period)

            # Prepare for prediction
            X_pred_raw = latest_data[feature_columns].values

            # Check for any NaN or infinite values and handle them
            if np.any(np.isnan(X_pred_raw)) or np.any(np.isinf(X_pred_raw)):
                st.warning("Data contains NaN or infinite values. Cleaning data...")
                X_pred_raw = np.nan_to_num(X_pred_raw, nan=0.0, posinf=1.0, neginf=-1.0)

            X_pred_scaled = feature_scaler.transform(X_pred_raw)

            # Reshape for LSTM input
            X_pred_scaled_reshaped = X_pred_scaled.reshape(X_pred_raw.shape[0], 1, X_pred_raw.shape[1])

            # Make predictions
            predicted_scaled = model.predict(X_pred_scaled_reshaped, verbose=0)
            predicted_volatility = target_scaler.inverse_transform(predicted_scaled).flatten()

            # Get actual values for comparison
            actual_volatility = data[target_column].tail(forecast_period).values

            # Create plot data with proper alignment
            if len(actual_volatility) == len(predicted_volatility[-forecast_period:]):
                plot_data = pd.DataFrame({
                    "Actual Volatility": actual_volatility,
                    "Predicted Volatility": predicted_volatility[-forecast_period:]
                }, index=data.index[-forecast_period:])

                # Plotting with Streamlit's line_chart
                st.line_chart(plot_data)
            else:
                st.warning("Mismatch in data lengths. Showing predicted volatility only.")
                pred_data = pd.DataFrame({
                    "Predicted Volatility": predicted_volatility[-forecast_period:]
                }, index=data.index[-forecast_period:])
                st.line_chart(pred_data)

            # --- Display Metrics ---
            st.write("### Model Metrics")

            # These are the metrics from the provided notebook for demonstration.
            # In a real-world app, you might re-evaluate on the latest data.
            if stock_option == "QQQ":
                metrics_data = {
                    'Metric': ['MSE', 'RMSE', 'MAE', 'R²'],
                    'QQQ Train': [0.000057, 0.007544, 0.005661, 0.752383],
                    'QQQ Test': [0.000109, 0.010437, 0.006647, 0.764282]
                }
            else:  # SPY
                metrics_data = {
                    'Metric': ['MSE', 'RMSE', 'MAE', 'R²'],
                    'SPY Train': [0.000036, 0.005980, 0.004293, 0.720412],
                    'SPY Test': [0.000088, 0.009363, 0.005570, 0.770471]
                }

            metrics_df = pd.DataFrame(metrics_data)
            st.table(metrics_df)

            # Display recent data
            st.write("### Recent Stock Data")
            st.dataframe(data.tail(10))

    except Exception as e:
        st.error(f"An error occurred: {str(e)}")
        st.write("Please check that all required files are present and the data can be loaded successfully.")

if __name__ == "__main__":
    main()